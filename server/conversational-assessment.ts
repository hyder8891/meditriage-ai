/**
 * Conversational Assessment Engine - HARDENED VERSION
 * 
 * Implements intelligent, context-aware conversational flow with:
 * - Robust JSON parsing with fallback questions
 * - Deterministic 10-step tracking
 * - Auto-recovery when AI fails
 */

import { invokeLLM } from "./_core/llm";
import { ConversationalContextVector } from "./conversational-context-vector";

// ============================================================================
// ğŸ›¡ï¸ FALLBACK QUESTIONS (If AI Fails, use these based on step)
// ============================================================================

const FALLBACK_QUESTIONS = [
  "What is the main symptom bothering you?",    // Step 0
  "How long have you had these symptoms?",      // Step 1
  "On a scale of 1-10, how severe is it?",      // Step 2
  "Where exactly is the pain or issue located?",// Step 3
  "Do you have a fever or high temperature?",   // Step 4
  "Have you taken any medications for this?",   // Step 5
  "Do you have any existing medical conditions?",// Step 6
  "Does anything make the symptoms better or worse?", // Step 7
  "Are you experiencing any other symptoms?",   // Step 8
  "Is there anything else I should know?",      // Step 9
];

const FALLBACK_QUESTIONS_AR = [
  "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ø°ÙŠ ÙŠØ²Ø¹Ø¬ÙƒØŸ",
  "Ù…Ù†Ø° Ù…ØªÙ‰ ÙˆØ£Ù†Øª ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ØŸ",
  "Ø¹Ù„Ù‰ Ù…Ù‚ÙŠØ§Ø³ Ù…Ù† 1 Ø¥Ù„Ù‰ 10ØŒ Ù…Ø§ Ù…Ø¯Ù‰ Ø´Ø¯ØªÙ‡ØŸ",
  "Ø£ÙŠÙ† Ø¨Ø§Ù„Ø¶Ø¨Ø· Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø£Ù„Ù… Ø£Ùˆ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©ØŸ",
  "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø­Ù…Ù‰ Ø£Ùˆ Ø¯Ø±Ø¬Ø© Ø­Ø±Ø§Ø±Ø© Ø¹Ø§Ù„ÙŠØ©ØŸ",
  "Ù‡Ù„ ØªÙ†Ø§ÙˆÙ„Øª Ø£ÙŠ Ø£Ø¯ÙˆÙŠØ© Ù„Ù‡Ø°Ø§ØŸ",
  "Ù‡Ù„ Ù„Ø¯ÙŠÙƒ Ø£ÙŠ Ø­Ø§Ù„Ø§Øª Ø·Ø¨ÙŠØ© Ù…ÙˆØ¬ÙˆØ¯Ø©ØŸ",
  "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø´ÙŠØ¡ ÙŠØ¬Ø¹Ù„ Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ø£ÙØ¶Ù„ Ø£Ùˆ Ø£Ø³ÙˆØ£ØŸ",
  "Ù‡Ù„ ØªØ¹Ø§Ù†ÙŠ Ù…Ù† Ø£ÙŠ Ø£Ø¹Ø±Ø§Ø¶ Ø£Ø®Ø±Ù‰ØŸ",
  "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ø£ÙŠ Ø´ÙŠØ¡ Ø¢Ø®Ø± ÙŠØ¬Ø¨ Ø£Ù† Ø£Ø¹Ø±ÙÙ‡ØŸ",
];

// ============================================================================
// Types
// ============================================================================

export interface ConversationMessage {
  role: "user" | "assistant";
  content: string;
  timestamp: number;
}

export interface ConversationContext {
  symptoms: string[];
  duration?: string;
  severity?: string;
  location?: string;
  aggravatingFactors?: string[];
  relievingFactors?: string[];
  associatedSymptoms?: string[];
  medicalHistory?: string[];
  medications?: string[];
  age?: number;
  gender?: string;
  questionCount?: number;
  stepCount?: number; // Track step count
  ruledOut?: string[]; // Items patient explicitly denied
  confirmedSymptoms?: string[]; // Symptoms patient explicitly confirmed
  conversationHistory?: Array<{ role: 'user' | 'assistant', content: string }>; // Full conversation history
}

export interface QuickReplyChip {
  text: string;
  textAr: string;
  value: string;
}

export interface AssessmentResponse {
  message: string;
  messageAr?: string;
  quickReplies?: QuickReplyChip[];
  conversationStage: "greeting" | "gathering" | "analyzing";
  triageResult?: {
    urgency: "emergency" | "urgent" | "routine" | "self_care";
    possibleConditions: Array<{
      name: string;
      nameAr: string;
      probability: number;
      reasoning: string;
      reasoningAr: string;
    }>;
    recommendations: string[];
    recommendationsAr: string[];
    redFlags?: string[];
    redFlagsAr?: string[];
  };
  context: ConversationContext;
}

// ============================================================================
// Main Assessment Function - HARDENED
// ============================================================================

export async function processConversationalAssessment(
  message: string,
  contextData: any
): Promise<AssessmentResponse> {
  
  // 1. Rehydrate the Memory
  const vector = new ConversationalContextVector(contextData);
  
  // 2. Add user message to conversation history
  vector.conversationHistory.push({ role: 'user', content: message });
  
  // 3. Determine Strategy based on Step Count
  const currentStep = vector.stepCount || 0;
  const isFinalStep = currentStep >= 9; // 0-9 = 10 steps

  console.log(`ğŸ“Š Assessment Step: ${currentStep + 1}/10 | isFinal: ${isFinalStep}`);

  // 3. Construct the "Doctor's Prompt"
  const systemPrompt = `
ROLE: You are Dr. Avicenna, an expert diagnostic AI for Tabibi Clinic.

TASK: Assess the patient's symptoms through a structured conversation.
CURRENT STEP: ${currentStep + 1}/10

PATIENT CONTEXT:
- Main Symptoms: ${vector.symptoms.join(", ") || "Unknown"}
- Duration: ${vector.duration || "Unknown"}
- Severity: ${vector.severity || "Unknown"}
- Location: ${vector.location || "Unknown"}
- Last User Input: "${message}"

INSTRUCTIONS:
${isFinalStep 
  ? `This is the final step. Provide:
     1. A triage recommendation (EMERGENCY, URGENT, ROUTINE, or SELF_CARE)
     2. Possible conditions with probabilities
     3. Clear recommendations
     4. Any red flags to watch for` 
  : `CRITICAL: Review the conversation history to see what questions you've already asked and what answers the patient provided.
     DO NOT repeat questions that have already been answered.
     Ask the SINGLE most important NEXT question to narrow down the diagnosis.
     Be empathetic but concise. Focus on gathering NEW critical information that hasn't been provided yet.`}

OUTPUT FORMAT:
You MUST return ONLY valid JSON. No markdown. No explanations. Just pure JSON.

${isFinalStep ? `
{
  "nextQuestion": "Thank you for providing all this information. Let me analyze your symptoms.",
  "nextQuestionAr": "Ø´ÙƒØ±Ø§Ù‹ Ù„ØªÙ‚Ø¯ÙŠÙ… ÙƒÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª. Ø¯Ø¹Ù†ÙŠ Ø£Ø­Ù„Ù„ Ø£Ø¹Ø±Ø§Ø¶Ùƒ.",
  "extractedData": {
    "symptoms": ["symptom1", "symptom2"],
    "duration": "duration if mentioned",
    "severity": "severity if mentioned",
    "location": "location if mentioned"
  },
  "triage": {
    "urgency": "ROUTINE",
    "possibleConditions": [
      {
        "name": "Condition Name",
        "nameAr": "Ø§Ø³Ù… Ø§Ù„Ø­Ø§Ù„Ø©",
        "probability": 75,
        "reasoning": "Why this condition is likely",
        "reasoningAr": "Ù„Ù…Ø§Ø°Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø© Ù…Ø­ØªÙ…Ù„Ø©"
      }
    ],
    "recommendations": ["Recommendation 1", "Recommendation 2"],
    "recommendationsAr": ["ØªÙˆØµÙŠØ© 1", "ØªÙˆØµÙŠØ© 2"],
    "redFlags": ["Red flag 1"],
    "redFlagsAr": ["Ø¹Ù„Ø§Ù…Ø© Ø­Ù…Ø±Ø§Ø¡ 1"]
  },
  "isFinal": true
}
` : `
{
  "nextQuestion": "The question to ask the patient in English",
  "nextQuestionAr": "Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
  "extractedData": {
    "symptoms": ["new symptom 1", "new symptom 2"],
    "duration": "extracted duration if present",
    "severity": "extracted severity if present",
    "location": "extracted location if present"
  },
  "isFinal": false
}
`}
`;

  try {
    // 4. Build conversation messages with full history
    const conversationMessages = [
      { role: "system" as const, content: systemPrompt },
      ...vector.conversationHistory.slice(-20).map(msg => ({ // Last 20 messages to avoid token limits
        role: msg.role,
        content: msg.content
      }))
    ];
    
    // 5. Call the AI with full conversation history
    const response = await invokeLLM({
      messages: conversationMessages
    });
    
    // 5. Parse the Response (Robust JSON Extraction)
    let content = response.choices?.[0]?.message?.content || "";
    
    // Handle array content (extract text from first element)
    if (Array.isArray(content)) {
      const textContent = content.find(c => c.type === "text");
      content = textContent?.text || "";
    }
    
    // Clean the string in case the AI wraps it in ```json ... ```
    const cleanJson = typeof content === "string" ? content.replace(/```json|```/g, '').trim() : "";
    const data = JSON.parse(cleanJson);

    console.log("âœ… AI Response parsed successfully:", data);
    
    // 6. Add assistant response to conversation history
    const assistantMessage = data.nextQuestion || data.message || "Let me analyze your symptoms.";
    vector.conversationHistory.push({ role: 'assistant', content: assistantMessage });

    // 7. Update Vector with AI's extraction
    if (data.extractedData) {
      if (data.extractedData.symptoms && Array.isArray(data.extractedData.symptoms)) {
        vector.updateSymptoms(data.extractedData.symptoms);
      }
      if (data.extractedData.duration) vector.duration = data.extractedData.duration;
      if (data.extractedData.severity) vector.severity = data.extractedData.severity;
      if (data.extractedData.location) vector.location = data.extractedData.location;
    }

    // 8. Increment Step
    vector.stepCount = currentStep + 1;

    // 9. Build Response
    if (data.isFinal && data.triage) {
      return {
        message: data.nextQuestion || "Based on your symptoms, here's my assessment:",
        messageAr: data.nextQuestionAr || "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£Ø¹Ø±Ø§Ø¶ÙƒØŒ Ø¥Ù„ÙŠÙƒ ØªÙ‚ÙŠÙŠÙ…ÙŠ:",
        conversationStage: "analyzing",
        triageResult: {
          urgency: data.triage.urgency.toLowerCase() as any,
          possibleConditions: data.triage.possibleConditions || [],
          recommendations: data.triage.recommendations || [],
          recommendationsAr: data.triage.recommendationsAr || [],
          redFlags: data.triage.redFlags,
          redFlagsAr: data.triage.redFlagsAr
        },
        context: vector.toJSON()
      };
    }

    return {
      message: data.nextQuestion,
      messageAr: data.nextQuestionAr,
      conversationStage: "gathering",
      context: vector.toJSON()
    };

  } catch (error) {
    console.error("âŒ AI Logic Failed:", error);
    console.error("Error details:", error instanceof Error ? error.message : String(error));
    
    // ğŸ”§ CRITICAL FIX: Increment step count BEFORE fallback to prevent infinite loops
    vector.stepCount = currentStep + 1;
    
    // Add fallback response to conversation history
    const fallbackQuestion = FALLBACK_QUESTIONS[Math.min(currentStep, FALLBACK_QUESTIONS.length - 1)];
    vector.conversationHistory.push({ role: 'assistant', content: fallbackQuestion });
    
    // ğŸ›¡ï¸ RECOVERY MECHANISM
    // If AI crashes, we manually advance the conversation using the hardcoded list.
    // ğŸ›¡ï¸ FALLBACK: Use deterministic questions (already added to history above)
    const fallbackQuestionAr = FALLBACK_QUESTIONS_AR[Math.min(currentStep, FALLBACK_QUESTIONS_AR.length - 1)];

    console.log(`ğŸ›¡ï¸ Using fallback question for step ${currentStep + 1}:`, vector.conversationHistory[vector.conversationHistory.length - 1].content);
    return {
      message: fallbackQuestion,
      messageAr: fallbackQuestionAr,
      conversationStage: "gathering",
      context: vector.toJSON() // Now includes incremented stepCount
    };
  }
}

// ============================================================================
// Emergency Detection (Unchanged)
// ============================================================================

const EMERGENCY_KEYWORDS = [
  // Cardiovascular
  "chest pain", "crushing chest", "heart attack", "can't breathe", "difficulty breathing",
  "severe chest pressure", "radiating pain", "arm pain with chest",
  
  // Neurological
  "stroke", "face drooping", "slurred speech", "sudden weakness", "severe headache",
  "worst headache", "thunderclap headache", "confusion", "loss of consciousness",
  "seizure", "convulsion",
  
  // Trauma
  "severe bleeding", "heavy bleeding", "uncontrolled bleeding", "head injury",
  "severe trauma", "broken bone", "compound fracture",
  
  // Respiratory
  "can't breathe", "choking", "blue lips", "gasping", "severe asthma attack",
  
  // Other Critical
  "suicide", "overdose", "poisoning", "severe allergic reaction", "anaphylaxis",
  "severe abdominal pain", "rigid abdomen", "coughing blood", "vomiting blood",
  "severe burn", "electric shock"
];

const EMERGENCY_KEYWORDS_AR = [
  "Ø£Ù„Ù… ÙÙŠ Ø§Ù„ØµØ¯Ø±", "Ù†ÙˆØ¨Ø© Ù‚Ù„Ø¨ÙŠØ©", "Ù„Ø§ Ø£Ø³ØªØ·ÙŠØ¹ Ø§Ù„ØªÙ†ÙØ³", "ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ØªÙ†ÙØ³",
  "Ø³ÙƒØªØ© Ø¯Ù…Ø§ØºÙŠØ©", "ØªØ¯Ù„ÙŠ Ø§Ù„ÙˆØ¬Ù‡", "ÙƒÙ„Ø§Ù… ØºÙŠØ± ÙˆØ§Ø¶Ø­", "Ø¶Ø¹Ù Ù…ÙØ§Ø¬Ø¦", "ØµØ¯Ø§Ø¹ Ø´Ø¯ÙŠØ¯",
  "Ù†Ø²ÙŠÙ Ø´Ø¯ÙŠØ¯", "Ù†Ø²ÙŠÙ ØºØ²ÙŠØ±", "Ø¥ØµØ§Ø¨Ø© ÙÙŠ Ø§Ù„Ø±Ø£Ø³", "ÙƒØ³Ø±", "Ø§Ø®ØªÙ†Ø§Ù‚",
  "Ø´ÙØ§Ù‡ Ø²Ø±Ù‚Ø§Ø¡", "Ø§Ù†ØªØ­Ø§Ø±", "Ø¬Ø±Ø¹Ø© Ø²Ø§Ø¦Ø¯Ø©", "ØªØ³Ù…Ù…", "Ø­Ø³Ø§Ø³ÙŠØ© Ø´Ø¯ÙŠØ¯Ø©",
  "Ø£Ù„Ù… Ø¨Ø·Ù†ÙŠ Ø´Ø¯ÙŠØ¯", "Ø³Ø¹Ø§Ù„ Ø¯Ù…", "Ù‚ÙŠØ¡ Ø¯Ù…ÙˆÙŠ", "Ø­Ø±Ù‚ Ø´Ø¯ÙŠØ¯", "ØµØ¯Ù…Ø© ÙƒÙ‡Ø±Ø¨Ø§Ø¦ÙŠØ©"
];

export function detectEmergency(message: string): boolean {
  const lowerMessage = message.toLowerCase();
  
  return EMERGENCY_KEYWORDS.some(keyword => lowerMessage.includes(keyword)) ||
         EMERGENCY_KEYWORDS_AR.some(keyword => message.includes(keyword));
}
